{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "\n",
    "import deepchem as dc\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from sklearn.metrics import r2_score as sklearn_r2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.nn import BatchNorm1d, HuberLoss, L1Loss, Linear, ModuleList, MSELoss\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import (\n",
    "    GATv2Conv,\n",
    "    GCN2Conv,\n",
    "    GraphNorm,\n",
    "    TopKPooling,\n",
    "    global_max_pool,\n",
    "    global_mean_pool,\n",
    "    summary,\n",
    ")\n",
    "from torcheval.metrics import R2Score\n",
    "from torcheval.metrics.functional import r2_score\n",
    "from twinning import twin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_graph_list(df: pd.DataFrame):\n",
    "    data_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        smiles = row[\"smiles\"]\n",
    "        label = row[\"MP\"]\n",
    "        featurizer = dc.feat.MolGraphConvFeaturizer(\n",
    "            use_edges=True, use_partial_charge=True\n",
    "        )\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            try:\n",
    "                f = featurizer._featurize(mol)\n",
    "                graph = f.to_pyg_graph()\n",
    "                graph.y = float(label)\n",
    "                graph.smiles = smiles\n",
    "                data_list.append(graph)\n",
    "            except IndexError:\n",
    "                pass\n",
    "    return data_list\n",
    "\n",
    "\n",
    "# Nodes\n",
    "\n",
    "\n",
    "def generate_graph_loader(df: pd.DataFrame):\n",
    "    data_list = _generate_graph_list(df)\n",
    "    graph_loader = DataLoader(\n",
    "        data_list,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    return graph_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:10:07] Explicit valence for atom # 25 H, 2, is greater than permitted\n",
      "[15:10:07] Explicit valence for atom # 25 H, 2, is greater than permitted\n",
      "[15:10:07] Explicit valence for atom # 25 H, 2, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "dataloder = generate_graph_loader(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # class nn.module\n",
    "# class GNN(torch.nn.Module):\n",
    "#     def __init__(self, model_parameters):\n",
    "#         # Loading params\n",
    "#         super().__init__()\n",
    "#         # hidden_size = model_parameters[\"hidden_size\"]\n",
    "#         # n_heads = model_parameters[\"n_heads\"]\n",
    "#         # self.n_layers = model_parameters[\"n_layers\"]\n",
    "#         # dropout_rate = model_parameters[\"dropout_rate\"]\n",
    "#         # top_k_ratio = model_parameters[\"top_k_ratio\"]\n",
    "#         # dense_size = model_parameters[\"dense_size\"]\n",
    "#         hidden_size = 16\n",
    "#         n_heads = 3\n",
    "#         self.n_layers = 0\n",
    "#         dropout_rate = 0.2\n",
    "#         top_k_ratio = 0.5\n",
    "#         dense_size = 8\n",
    "#         # Module lists\n",
    "#         self.conv_layers = ModuleList([])\n",
    "#         self.transf_layers = ModuleList([])\n",
    "#         self.pooling_layers = ModuleList([])\n",
    "#         self.gn_layers = ModuleList([])\n",
    "#         # Initial aggregation layer\n",
    "#         self.conv1 = GATv2Conv(\n",
    "#             in_channels=31,\n",
    "#             out_channels=hidden_size,\n",
    "#             heads=n_heads,\n",
    "#             dropout=dropout_rate,\n",
    "#             edge_dim=11,\n",
    "#         )\n",
    "#         self.transf1 = Linear(hidden_size * 3, hidden_size)\n",
    "#         self.gn1 = GraphNorm(hidden_size)\n",
    "#         self.pooling_layer1 = TopKPooling(hidden_size, ratio=top_k_ratio)\n",
    "#         # Internal layers\n",
    "#         for _ in range(self.n_layers):\n",
    "#             self.conv_layers.append(\n",
    "#                 GATv2Conv(\n",
    "#                     in_channels=hidden_size,\n",
    "#                     out_channels=hidden_size,\n",
    "#                     heads=n_heads,\n",
    "#                     dropout=dropout_rate,\n",
    "#                     edge_dim=11,\n",
    "#                 )\n",
    "#             )\n",
    "#             self.transf_layers.append(Linear(hidden_size * n_heads, hidden_size))\n",
    "#             self.gn_layers.append(GraphNorm(hidden_size))\n",
    "#             self.pooling_layers.append(TopKPooling(hidden_size, ratio=top_k_ratio))\n",
    "#         # Linear layers\n",
    "#         self.linear1 = Linear(2 * hidden_size, dense_size)\n",
    "#         self.linear2 = Linear(dense_size, int(dense_size / 2))\n",
    "#         self.linear3 = Linear(int(dense_size / 2), 1)\n",
    "\n",
    "#     def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "#         global_representation = []\n",
    "#         # Aggregation block\n",
    "#         x = self.conv1(x, edge_index, edge_attr)\n",
    "#         x = torch.relu(self.transf1(x))\n",
    "#         x = self.gn1(x, batch_index)\n",
    "#         # x, edge_index, edge_attr, batch_index, _, _ = self.pooling_layer1(\n",
    "#         #     x, edge_index, edge_attr, batch_index\n",
    "#         # )\n",
    "#         global_representation.append(\n",
    "#             torch.cat(\n",
    "#                 [global_mean_pool(x, batch_index), global_max_pool(x, batch_index)],\n",
    "#                 dim=1,\n",
    "#             )\n",
    "#         )\n",
    "#         # Internal layers\n",
    "#         for i in range(self.n_layers):\n",
    "#             x = self.conv_layers[i](x, edge_index, edge_attr)\n",
    "#             x = F.leaky_relu(self.transf_layers[i](x))\n",
    "#             x = self.gn_layers[i](x, batch_index)\n",
    "#             x, edge_index, edge_attr, batch_index, _, _ = self.pooling_layers[i](\n",
    "#                 x, edge_index, edge_attr, batch_index\n",
    "#             )\n",
    "#             global_representation.append(\n",
    "#                 torch.cat(\n",
    "#                     [global_mean_pool(x, batch_index), global_max_pool(x, batch_index)],\n",
    "#                     dim=1,\n",
    "#                 )\n",
    "#             )\n",
    "#         # Output block\n",
    "#         x = sum(global_representation)\n",
    "#         x = torch.relu(self.linear1(x))\n",
    "#         x = F.dropout(x, p=0.2, training=self.training)\n",
    "#         x = torch.relu(self.linear2(x))\n",
    "#         x = F.dropout(x, p=0.2, training=self.training)\n",
    "#         x = self.linear3(x)\n",
    "#         return x\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(31, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "\n",
    "class GNN_L(L.LightningModule):\n",
    "    def __init__(self, model, trainer_parameters):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = trainer_parameters[\"lr\"]\n",
    "        self.weight_decay = trainer_parameters[\"weight_decay\"]\n",
    "        self.scheduler_gamma = trainer_parameters[\"scheduler_gamma\"]\n",
    "        self.loss_fn = MSELoss()\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index):\n",
    "        return self.model(\n",
    "            x.float(), edge_index, batch_index\n",
    "        ).squeeze()\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        preds = self(\n",
    "            batch.x.float(), batch.edge_index, batch.batch\n",
    "        ).squeeze()\n",
    "        target = batch.y.float()\n",
    "        loss = self.loss_fn(preds, target)\n",
    "        r2 = r2_score(preds, target)\n",
    "        self.log(\"r2\", r2)\n",
    "        self.log(\"loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), lr=self.lr, weight_decay=self.weight_decay\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer, gamma=self.scheduler_gamma\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"epoch\"}]\n",
    "\n",
    "\n",
    "def train_model(train_dataloader, trainer_parameters):\n",
    "    L.seed_everything(42)\n",
    "    model = GNN_L(GCN(64), trainer_parameters)\n",
    "    early_stopping = EarlyStopping(\"loss\", patience=100)\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=100,\n",
    "        callbacks=[early_stopping, lr_monitor],\n",
    "        log_every_n_steps=5,\n",
    "        logger=True,\n",
    "        deterministic=True,\n",
    "        accumulate_grad_batches=1,\n",
    "    )\n",
    "    trainer.fit(model=model, train_dataloaders=train_dataloader)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_parameters = {\"lr\": 0.001,\n",
    "                      \"weight_decay\": 0.,\n",
    "                      \"scheduler_gamma\": 0.99}\n",
    "model_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | model   | GCN     | 10.4 K | train\n",
      "1 | loss_fn | MSELoss | 0      | train\n",
      "--------------------------------------------\n",
      "10.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "10.4 K    Total params\n",
      "0.042     Total estimated model params size (MB)\n",
      "c:\\Users\\01121272\\Desktop\\Projects\\gnn-mp-model\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 29/29 [00:00<00:00, 32.33it/s, v_num=15]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 29/29 [00:00<00:00, 31.83it/s, v_num=15]\n"
     ]
    }
   ],
   "source": [
    "model = train_model(dataloder, trainer_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[39, 31], edge_index=[2, 76], edge_attr=[76, 11], y=[1], smiles='CCCCCCCCCCCCCC[N+](C)(C)Cc1ccccc1.FC(F)(F)S(=O)(=O)[N-]S(=O)(=O)C(F)(F)F')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([289.4050, 292.0450, 289.4050, 297.7302, 287.9824, 315.9386, 289.4050,\n",
       "        343.5855, 344.1520, 285.9215, 312.0751, 314.0991, 354.7935, 289.4050,\n",
       "        309.6705, 289.4050, 267.6820, 281.7561, 313.6778, 324.7451, 289.4050,\n",
       "        285.7552, 315.2130, 369.7042, 276.5990, 312.0751, 289.4050, 289.4050,\n",
       "        276.5990, 307.1325, 289.4050, 315.1769], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch.x.float(), batch.edge_index, batch.batch\n",
    "        ).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([288.0000, 243.2000, 287.9000, 318.2000, 275.2000, 298.2000, 253.2000,\n",
       "        432.2000, 414.4000, 306.2000, 283.2000, 250.8000, 355.2000, 325.2000,\n",
       "        335.0000, 314.2000, 259.7000, 342.2000, 217.6000, 304.2000, 282.2000,\n",
       "        428.0000, 307.1000, 390.2000, 262.2000, 294.7000, 299.1000, 302.2000,\n",
       "        285.2000, 371.2000, 260.2000, 254.9000])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2251)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(input=preds, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.350647"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_error(target.numpy(), preds.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
